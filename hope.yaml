access_points:
  - 192.168.2.43
access_point_controller: http://192.168.2.10:8080
nodes:
  - name: home-master-01
    role: master
    hostname: 192.168.1.31
    user: root
  - name: home-node-01
    role: node
    hostname: 192.168.1.30
    user: root
loglevel: trace
pod_network_cidr: 10.244.0.0/16
# Resource list of all things to deploy to the cluster, and the order in which
#   to deploy them.
# Resources can be defined in the following different ways:
resources:
  # Using a url to a file that can be passed directly to kubectl apply -f.
  # These can be http(s):// urls, or just file path.
  # It will always be preferred that urls appearing here are to stable yaml
  #   files available on the Internet, rather than anything loaded from the
  #   local machine.
  # Local paths can be used for testing, but ultimately, whatever ends up
  #   being deployed should be done so using GitHub tags/releases.
  # Every resource can provide a set of tags that will allow for the
  #   deployment of multiple resources without naming every resource
  #   explicitly.
  - name: calico
    file: https://docs.projectcalico.org/manifests/calico.yaml
    tags: [network]
  # Inline definitions are also supported.
  # These values have to be provided as yaml strings under the `inline` key.
  # Values passed in through `inline` will be fed through `envsubst` before
  #   being passed off to kubectl, so any values that are dynamic/secret can be
  #   passed in through using environment variables.
  # Values that envsubst will be required to populate are provided in the
  #   parameters list.
  # If no parameters are provided, envsubst is skipped.
  # As is the case with anything else hitting kubectl apply -f, multiple
  #   objects can be provided by --- separators.
  - name: load-balancer-config
    inline: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        namespace: metallb-system
        name: config
      data:
        config: |
          address-pools:
          - name: default
            protocol: layer2
            addresses:
            - 192.168.1.16-192.168.1.24
      ---
      apiVersion: v1
      data:
        secretkey: ${METALLB_SYSTEM_MEMBERLIST_SECRET_KEY}
      kind: Secret
      metadata:
        creationTimestamp: null
        name: memberlist
        namespace: metallb-system
    parameters:
      - METALLB_SYSTEM_MEMBERLIST_SECRET_KEY
    tags: [network]
  # Build and push a docker image to the registry.
  # Doesn't include a kubectl command at all, so that can be done in a step
  #   after a step like this appears.
  # Hope will optionally try to pull the image from the registry before
  #   building it in an attempt to save some compute time rebuilding layers 
  #   that haven't changed since the last push.
  # Pull from source registry can be done in similar ways to Kubernetes'
  #   Always and IfNotPresent with the "always", if "if-not-present" values.
  # Like Kubernetes, defaults to "if-not-present".
  # Because docker builds tend to require a bit more state in them, providing a
  #   local path is all that's currently supported.
  # Now that Docker Hub has rolled out rate limits on their APIs, a Docker
  #   build step also has the option to just copy an existing source tag, and
  #   push it to the local registry.
  - name: build-some-image
    build:
      path: some-dir-with-dockerfile
      pull: always
      tag: registry.internal.aleemhaji.com/example-repo:latest
    tags: [app1]
  - name: copy-some-image
    build:
      source: python:3.7
      pull: if-not-present
      tag: registry.internal.aleemhaji.com/python:3.7
    tags: [dockercache]
  # When a spec comes with an initialization procedure, a job type can be used.
  # These will wait until the job with the specified name is completed.
  # If the job fails, the deployment stops so that other resources that may
  #   depend on the job aren't pushed before the job has completed
  #   successfully.
  # For the sake of idempotence, jobs tested using this mechanism shouldn't be
  #   set to be deleted by any mechanism.
  - name: wait-for-some-kind-of-job
    job: init-the-database
    tags: [database]
  # If something needs to be executed against pods of an existing set of pods,
  #   the exec resource will run a script against a running instance.
  # A timeout can optionally be provided to wait for pods to start.
  - name: exec-in-a-running-pod
    exec:
      selector: deploy/mysql
      timeout: 60s
      command:
        - mysql
        - -e
        - select 1;
    tags: [database]
# Jobs contains a collection of specifications of templated jobs that can be
#   run on demand in the cluster.
# These jobs shouldn't be associated to the deployment of any particular
#   service, or be a part of the main execution of a service.
# These should be used for more operational repairs/manipulations.
# Jobs should use generateName to ensure that unique instances are created when
#   called upon, rather than failing to create because of duplicate names.
# Parameters for these jobs should be provided using the -p X=Y flag; these
#   parameters will be populated in the source file using envsubst.
# Arguments not provided in the args list will not be populated in the given
#   file, as those may be arguments intended to be populated through the job's
#   spec.
# Jobs will be started, and logs will be streamed to the client.
jobs:
  - name: some-unscheduled-job
    file: /path/to/some/job.yaml
    parameters:
      - SOMETHING_TO_POPULATE
